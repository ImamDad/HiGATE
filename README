# HiGATE: Hierarchical Graph Attention with Cross-Level Interaction

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?logo=PyTorch&logoColor=white)](https://pytorch.org/)
[![Paper](https://img.shields.io/badge/Paper-IEEE%20TMI-blue)](https://ieeexplore.ieee.org/document/XXXXXXX)

Official implementation of **HiGATE** (Hierarchical Graph Attention with Cross-Level Interaction), a novel framework for multi-scale computational pathology that achieves state-of-the-art performance on nuclear segmentation and classification tasks.

> **IEEE Transactions on Medical Imaging** \
> *HiGATE: Hierarchical Graph Attention with Cross-Level Interaction for Explainable Multi-Scale Computational Pathology*

## 📖 Abstract

The hierarchical organization of tissue, spanning from individual cells to tissue architecture, is fundamental to pathological diagnosis. While Hierarchical Graph Neural Networks (HGNNs) have shown promise for modeling this structure, existing methods often rely on static or sequential processing, failing to capture the dynamic, bidirectional interactions that mirror a pathologist's integrative reasoning.

HiGATE introduces a dual-graph architecture that concurrently models fine-grained cellular interactions and coarse-grained tissue regions through adaptive clustering. Its core innovation is a **Cross-Level Attention mechanism** that enables dynamic, bidirectional message passing between cellular and tissue hierarchies. Extensive evaluation demonstrates state-of-the-art performance with **91.3% accuracy** and **0.896 F1-score** on PanNuke, with exceptional generalizability in zero-shot validation on MoNuSeg (**0.841 Dice coefficient**).

## 🚀 Key Features

- **🔬 Dual-Graph Architecture**: Simultaneous modeling of Cell Graph (k-NN) and Tissue Graph (adaptive DBSCAN)
- **🔄 Cross-Level Attention**: Dynamic bidirectional message passing between hierarchies
- **🎯 Adaptive Clustering**: Semantic tissue region identification via DBSCAN with dynamic parameters
- **📊 Multi-Modal Features**: Integration of DINOv2 visual (768D) + morphological (6D) + StarDist nuclear (12D) features
- **🔍 Inherent Explainability**: Multi-scale interpretability aligned with pathological reasoning
- **⚡ State-of-the-Art Performance**: 91.3% accuracy on PanNuke, 0.841 Dice on MoNuSeg (zero-shot)
- **🏥 Clinical Relevance**: Explanations that bridge cellular morphology with tissue-level context

## 🏗️ Architecture

![HiGATE Architecture](docs/architecture.png)

HiGATE's architecture consists of four core components matching the research paper:

### 1. Multi-modal Feature Extraction (Section 3.2)
- **DINOv2 Visual Features**: 768-dimensional features from pre-trained Vision Transformer
- **Morphological Features**: 6 geometric descriptors (area, perimeter, eccentricity, solidity, extent, orientation)
- **Nuclear Features**: 12 StarDist features (radial distances, axis ratio, area discrepancy, intensity features)

### 2. Hierarchical Graph Construction (Section 3.3)
- **Cell Graph**: Adaptive k-NN connectivity based on cellular density
- **Tissue Graph**: Adaptive DBSCAN clustering with dynamic parameters (ε = 95th percentile of k-distances)

### 3. Cross-Level Attention (Section 3.4)
- **Bottom-Up Attention**: Tissue nodes attend to constituent cells
- **Top-Down Attention**: Cells attend to tissue context with GRU refinement
- **Iterative Refinement**: 3 layers of bidirectional message passing

### 4. Multi-Scale Readout (Section 3.5)
- **Dual Pooling**: Mean + max pooling for both cell and tissue graphs
- **Classification**: MLP head with 512D combined embeddings → 5-class prediction

## 📊 Results

### PanNuke Performance (Table 2)
| Method | Accuracy | F1-Score | AUROC | AUPRC |
|--------|----------|----------|-------|-------|
| ResNet-50 | 84.1% | 0.832 | 0.912 | 0.801 |
| ViT-B/16 | 86.2% | 0.851 | 0.928 | 0.832 |
| Patch-GCN | 87.6% | 0.863 | 0.937 | 0.858 |
| HACT-Net | 89.1% | 0.879 | 0.945 | 0.872 |
| **HiGATE** | **91.3%** | **0.896** | **0.958** | **0.901** |

### External Validation on MoNuSeg (Table 7)
| Method | Dice | AJI | PQ | Mean F1 |
|--------|------|-----|----|---------|
| U-Net (in-domain) | 0.834 | 0.680 | 0.661 | 0.819 |
| HACT-Net (zero-shot) | 0.796 | 0.601 | 0.588 | 0.782 |
| Hover-Net | 0.810 | 0.592 | 0.561 | 0.781 |
| **HiGATE (zero-shot)** | **0.841** | **0.632** | **0.598** | **0.819** |

### Ablation Studies (Table 5)
| Model Variant | PanNuke Acc. | PanNuke F1 | MoNuSeg Dice |
|---------------|--------------|------------|--------------|
| Full HiGATE | **0.913** | **0.896** | **0.841** |
| w/o Visual Features | 0.875 | 0.858 | 0.781 |
| w/o Tissue Graph | 0.865 | 0.847 | 0.768 |
| w/o Cross-Level Attention | 0.879 | 0.861 | 0.798 |
| Fixed Grid Clustering | 0.870 | 0.852 | 0.776 |

## 📥 Installation

### Prerequisites
- Python 3.8+
- CUDA 11.0+ (for GPU acceleration)
- 16GB+ RAM recommended

### Quick Install
```bash
# Clone repository
git clone https://github.com/ImamDad/HiGATE.git
cd HiGATE

# Run setup script (installs all dependencies)
python setup_environment.py

# Verify installation
python -c "import torch; print(f'PyTorch: {torch.__version__}'); import torch_geometric; print('PyG installed successfully')"
```

### Manual Installation
```bash
# Create conda environment
conda create -n higate python=3.8
conda activate higate

# Install PyTorch (choose appropriate version for your CUDA)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install PyTorch Geometric
pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html
pip install torch-geometric

# Install other requirements
pip install -r requirements.txt
```

## 📁 Dataset Setup

### PanNuke Dataset
1. Download PanNuke dataset from [official website](https://warwick.ac.uk/fac/cross_fac/tia/data/pannuke)
2. Organize the data as follows:
```
data/pannuke/
├── fold1/  # Training (as per paper)
│   ├── extracted_images_npy/
│   ├── extracted_masks/
│   └── cell_counts.csv
├── fold2/  # Validation
└── fold3/  # Testing
```

### MoNuSeg Dataset (for external validation)
1. Download from [MoNuSeg Challenge](https://monuseg.grand-challenge.org/Data/)
2. Place in `data/external/monuseg/`

## 🏃‍♂️ Quick Start

### 1. Generate Graph Data
```bash
# Generate graphs for all folds (this may take several hours)
python scripts/generate_graphs.py --fold fold1
python scripts/generate_graphs.py --fold fold2  
python scripts/generate_graphs.py --fold fold3

# Or generate all at once
python main.py --mode generate_graphs
```

### 2. Train HiGATE Model
```bash
# Train with default parameters (matches paper)
python main.py --mode train

# Train with custom configuration
python main.py --mode train --config configs/custom.yaml
```

### 3. Evaluate on Test Set
```bash
# Evaluate trained model
python main.py --mode evaluate --model-path saved_models/best_model.pth
```

### 4. Generate Explanations
```bash
# Generate multi-scale explanations for samples
python main.py --mode explain --model-path saved_models/best_model.pth --num-samples 5
```

### 5. External Validation
```bash
# Validate on MoNuSeg dataset
python main.py --mode validate --model-path saved_models/best_model.pth
```

## ⚙️ Configuration

Key parameters in `config.py` (matching paper specifications):

```python
# Model Architecture (Section 3.4)
HIDDEN_DIM = 128           # GNN hidden dimension
NUM_LAYERS = 3             # Number of GNN layers  
NUM_HEADS = 8              # Attention heads
DROPOUT_RATE = 0.2         # Dropout rate
CLUSTERING_DIM = 64        # Feature projection for clustering

# Feature Dimensions (Section 3.2)
CNN_FEATURE_DIM = 768      # DINOv2 features
MORPH_FEATURE_DIM = 6      # Morphological features
NUCLEAR_FEATURE_DIM = 12   # StarDist features
CELL_FEATURE_DIM = 786     # Combined features

# Training (Section 4.1)
BATCH_SIZE = 16
LEARNING_RATE = 1e-4
WEIGHT_DECAY = 1e-5
EPOCHS = 100
FOCAL_LOSS_GAMMA = 2.0     # Class-balanced focal loss
```

## 📁 Project Structure

```
HiGATE/
├── 📄 README.md                 # This file
├── ⚙️ config.py                 # Main configuration
├── 🚀 main.py                   # Entry point
├── 🔧 setup_environment.py      # Environment setup
├── 📊 requirements.txt          # Dependencies
│
├── 🔬 data_processing/          # Data loading and preprocessing
│   ├── dataset.py              # PanNuke dataset loader
│   ├── feature_extraction.py   # Multi-modal feature extraction
│   ├── graph_construction.py   # Hierarchical graph building
│   ├── build_graphs.py         # Graph generation pipeline
│   └── transforms.py           # Data transformations
│
├── 🧠 models/                   # Model architectures
│   ├── higate.py               # Main HiGATE model
│   ├── hierarchical_gnn.py     # Hierarchical GNN components
│   ├── attention_modules.py    # Cross-level attention
│   ├── classifier.py           # Classification heads
│   └── dino/                   # DINOv2 integration
│
├── 🏋️ training/                # Training utilities
│   ├── trainer.py              # Main training loop
│   ├── evaluate.py             # Evaluation metrics
│   ├── metrics.py              # Performance metrics
│   ├── explainability.py       # XAI methods
│   └── external_validation.py  # Cross-dataset validation
│
├── 📜 scripts/                 # Utility scripts
│   ├── generate_graphs.py      # Graph data generation
│   ├── calculate_morph_stats.py # Feature statistics
│   └── visualize_results.py    # Results visualization
│
├── 💾 saved_models/            # Trained model checkpoints
├── 📈 results/                 # Output results and plots
└── 📚 docs/                    # Documentation
```

## 🔍 Explainability

HiGATE provides inherent multi-scale explanations:

```python
from training.explainability import HierarchicalGNNExplainer

# Initialize explainer
explainer = HierarchicalGNNExplainer("saved_models/best_model.pth")

# Generate explanations for a sample
explanations = explainer.multi_method_explain(sample)

# Visualize multi-scale rationales
explainer.visualize_explanations(explanations, "explanation_report.pdf")
```

**Explanation Methods:**
- Node and edge importance analysis
- Cross-level attention visualization  
- Hierarchical Graph-LRP
- Feature contribution analysis
- Multi-scale saliency maps

## 📈 Reproducing Paper Results

### Exact Experimental Setup
```bash
# 1. Generate graphs with paper parameters
python scripts/generate_graphs.py --fold fold1
python scripts/generate_graphs.py --fold fold2
python scripts/generate_graphs.py --fold fold3

# 2. Train HiGATE (100 epochs, early stopping patience 20)
python main.py --mode train

# 3. Evaluate on test set (fold3)
python main.py --mode evaluate --model-path saved_models/best_model.pth

# 4. External validation on MoNuSeg
python main.py --mode validate --model-path saved_models/best_model.pth
```

### Expected Output
```
Training completed: 91.3% accuracy, 0.896 F1-score
Test results: 90.8% accuracy, 0.892 F1-score  
MoNuSeg zero-shot: 0.841 Dice, 0.632 AJI
```

## 🛠️ Customization

### Using Different Datasets
```python
from data_processing.dataset import CustomDataset
from models.higate import HiGATE

# Create custom dataset
dataset = CustomDataset(your_data_path)

# Initialize HiGATE with custom config
model = HiGATE(custom_config)
```

### Modifying Architecture
```python
from models.higate import HiGATE
from models.attention_modules import CustomAttention

# Custom attention mechanism
model = HiGATE(config)
model.cross_attention = CustomAttention(hidden_dim=256, num_heads=16)
```

## 🤝 Contributing

We welcome contributions! Please feel free to submit:

- 🐛 Bug reports and feature requests via [GitHub Issues](https://github.com/ImamDad/HiGATE/issues)
- 🔧 Code contributions via Pull Requests
- 📖 Documentation improvements
- 🎯 New dataset integrations

### Development Setup
```bash
# Fork and clone the repository
git clone https://github.com/your-username/HiGATE.git
cd HiGATE

# Create development branch
git checkout -b feature/your-feature-name

# Install in development mode
pip install -e .
```

## 📄 Citation

If you use HiGATE in your research, please cite our paper:

```bibtex
@article{imam2024higate,
  title={HiGATE: Hierarchical Graph Attention with Cross-Level Interaction for Explainable Multi-Scale Computational Pathology},
  author={Imam, Dad and Jianfeng, He},
  journal={IEEE Transactions on Medical Imaging},
  volume={43},
  number={8},
  pages={1--15},
  year={2024},
  publisher={IEEE}
}
```

## 🙏 Acknowledgments

- **National Natural Science Foundation of China** (No. 82160347) for financial support
- **Chinese Scholarship Council (CSC)** for organizing this study
- **Kunming University of Science and Technology** for providing research environment and technical support
- **University of Balochistan** for academic support
- Contributors to the PanNuke and MoNuSeg datasets

## 📜 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 📞 Contact

- **Dad Imam** - [imamdad.csit@uob.edu.pk](mailto:imamdad.csit@uob.edu.pk)
- **He Jianfeng** (Corresponding) - [jfenghe@kust.edu.cn](mailto:jfenghe@kust.edu.cn)

## 🔗 Links

- 📖 [Paper](https://ieeexplore.ieee.org/document/XXXXXXX) - IEEE TMI publication
- 💻 [GitHub](https://github.com/ImamDad/HiGATE) - Source code
- 🐛 [Issues](https://github.com/ImamDad/HiGATE/issues) - Bug reports and feature requests
- 💬 [Discussions](https://github.com/ImamDad/HiGATE/discussions) - Questions and community discussions

---

<div align="center">
  
*🌟 If you find HiGATE useful for your research, please give it a star! 🌟*

</div>
